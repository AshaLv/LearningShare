{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 5)\n",
      "   用户ID  用户年龄 用户性别        用户职业   用户邮编\n",
      "0     1    24    M  technician  85711\n",
      "1     2    53    F       other  94043\n",
      "2     3    23    M      writer  32067\n",
      "3     4    24    M  technician  43537\n",
      "4     5    33    F       other  15213\n"
     ]
    }
   ],
   "source": [
    "#读用户数据表:\n",
    "u_cols = ['用户ID','用户年龄','用户性别','用户职业','用户邮编']\n",
    "users = pd.read_csv('./ml-100k/u.user', sep='|', names=u_cols, encoding='utf-8')\n",
    "print(users.shape)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n",
      "   用户ID  电影ID  评分       评分日期\n",
      "0   196   242   3  881250949\n",
      "1   186   302   3  891717742\n",
      "2    22   377   1  878887116\n",
      "3   244    51   2  880606923\n",
      "4   166   346   1  886397596\n"
     ]
    }
   ],
   "source": [
    "#读评分数据表:\n",
    "r_cols = ['用户ID','电影ID','评分','评分日期']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols,encoding='utf-8')\n",
    "print(ratings.shape)\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 24)\n",
      "   电影ID                电影名          上映期  录入日期  \\\n",
      "0     1   Toy Story (1995)  01-Jan-1995   NaN   \n",
      "1     2   GoldenEye (1995)  01-Jan-1995   NaN   \n",
      "2     3  Four Rooms (1995)  01-Jan-1995   NaN   \n",
      "3     4  Get Shorty (1995)  01-Jan-1995   NaN   \n",
      "4     5     Copycat (1995)  01-Jan-1995   NaN   \n",
      "\n",
      "                                              IMDB网址  未知  动作  冒险  动画  儿童片  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...   0   0   0   1    1   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...   0   1   1   0    0   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...   0   0   0   0    0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...   0   1   0   0    0   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)   0   0   0   0    0   \n",
      "\n",
      "   ...   科幻片  悲剧  鬼片  音乐剧  悬疑片  浪漫片  科技片  恐怖片  战争片  西部作品  \n",
      "0  ...     0   0   0    0    0    0    0    0    0     0  \n",
      "1  ...     0   0   0    0    0    0    0    1    0     0  \n",
      "2  ...     0   0   0    0    0    0    0    1    0     0  \n",
      "3  ...     0   0   0    0    0    0    0    0    0     0  \n",
      "4  ...     0   0   0    0    0    0    0    1    0     0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#读电影数据表\n",
    "i_cols = ['电影ID','电影名','上映期','录入日期','IMDB网址','未知','动作','冒险','动画','儿童片',\n",
    "         '喜剧','犯罪','纪录片','戏剧','科幻片','悲剧','鬼片','音乐剧','悬疑片','浪漫片',\n",
    "         '科技片','恐怖片','战争片','西部作品']\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols, encoding='utf-8')\n",
    "print(items.shape)\n",
    "print(items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9430, 4)\n",
      "   用户ID  电影ID  评分       评分日期\n",
      "0     1    20   4  887431883\n",
      "1     1    33   4  878542699\n",
      "2     1    61   4  878542420\n",
      "3     1   117   3  874965739\n",
      "4     1   155   2  878542201\n"
     ]
    }
   ],
   "source": [
    "#从10万的真实评分数据表中拿出9430条做为模型的测试数据\n",
    "\n",
    "#这测试数据是每一个用户对10个电影的评分,所以943个人产生9430条数据\n",
    "\n",
    "#读取测试评分数据表\n",
    "r_cols = ['用户ID','电影ID','评分','评分日期']\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test',sep='\\t',names=r_cols,encoding='utf-8')\n",
    "print(ratings_test.shape)\n",
    "print(ratings_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 4)\n",
      "   用户ID  电影ID  评分       评分日期\n",
      "0     1     1   5  874965758\n",
      "1     1     2   3  876893171\n",
      "2     1     3   4  878542960\n",
      "3     1     4   3  876893119\n",
      "4     1     5   3  889751712\n"
     ]
    }
   ],
   "source": [
    "#剩余的90570条数据拿来制作我们的推荐模型\n",
    "\n",
    "ratings_train = pd.read_csv('ml-100k/ua.base',sep='\\t',names=r_cols,encoding='utf-8')\n",
    "print(ratings_train.shape)\n",
    "print(ratings_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以上我们已经准备好了建立推荐模型所有数据了,LETS GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唯一用户数量:  943\n"
     ]
    }
   ],
   "source": [
    "#我们如果是基于用户与用户间的相似度推荐模型的话,先看看用户数据表剔除重复用户后的用户量\n",
    "\n",
    "n_users = ratings.用户ID.unique().shape[0]\n",
    "print(\"不重复用户数量: \",n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不重复电影数量:  1682\n"
     ]
    }
   ],
   "source": [
    "#我们如果是基于电影与电影间的相似度推荐模型的话,先看看电影数据表剔除重复用户后的用户量\n",
    "\n",
    "n_items = ratings.电影ID.unique().shape[0]\n",
    "print(\"不重复电影数量: \",n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "[[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#现在我们会建立以Y轴为用户ID，X轴为电影ID的矩阵（理解成数据表也行,但是矩阵会更客观）\n",
    "\n",
    "user_movie_matrix = np.zeros((n_users, n_items)) #建立943行1682列的数值被0填满的矩阵,总共有1586126空\n",
    "\n",
    "#现在为Y轴填充用户ID(0-最大)，为X轴填充电影ID(0-最大)\n",
    "for line in ratings.itertuples():\n",
    "    #line[1]为用户ID,减去1是为了让用户以0作为index的起始\n",
    "    #line[2]为电影ID，减去1是为了让电影以0作为index的其实\n",
    "    #line[3]为该用户对该电影的评分, 该用户确定了行的位置,该电影确定了列的位置,然后将评分值塞到正确位置上\n",
    "    user_movie_matrix[line[1]-1, line[2]-1] = line[3] #拿10万带有评分的去塞空，所以会有很多打分是0的，\n",
    "    #说明用户还没有对这个电影评过分\n",
    "\n",
    "    \n",
    "print(user_movie_matrix.shape)\n",
    "print(user_movie_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 943)\n",
      "[[0.         0.83306902 0.95254046 ... 0.85138306 0.82049212 0.60182526]\n",
      " [0.83306902 0.         0.88940868 ... 0.83851522 0.82773219 0.89420212]\n",
      " [0.95254046 0.88940868 0.         ... 0.89875744 0.86658385 0.97344413]\n",
      " ...\n",
      " [0.85138306 0.83851522 0.89875744 ... 0.         0.8983582  0.90488042]\n",
      " [0.82049212 0.82773219 0.86658385 ... 0.8983582  0.         0.81753534]\n",
      " [0.60182526 0.89420212 0.97344413 ... 0.90488042 0.81753534 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#现在建立好以用户ID为Y轴，以电影ID为X轴的矩阵后,我们就可以开始计算相似度了\n",
    "\n",
    "#我们可以使用sklearn的pairwise_distance的函数计算cosine相似度\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "#每一个用户以列数据,就是该用户对所有电影的评分,就是每一个用户所在的行,与其它行做cosine相似度的计算，\n",
    "#该函数封装了矩阵的“点积相乘”（如果概念跟学名没有搞错的话...）\n",
    "user_similarity = pairwise_distances(user_movie_matrix,metric='cosine') #得到每个用户与其它用户相似度的矩阵\n",
    "print(user_similarity.shape)\n",
    "print(user_similarity)\n",
    "#同一个用户相似度被弄成0\n",
    "\n",
    "#同一个用户难道不是百分百相似吗？没事，不管它：》 下面预测评分模型的时候0的作用就体现出来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 1682)\n",
      "[[0.         0.59761782 0.66975521 ... 1.         0.95281693 0.95281693]\n",
      " [0.59761782 0.         0.72693082 ... 1.         0.92170064 0.92170064]\n",
      " [0.66975521 0.72693082 0.         ... 1.         1.         0.90312495]\n",
      " ...\n",
      " [1.         1.         1.         ... 0.         1.         1.        ]\n",
      " [0.95281693 0.92170064 1.         ... 1.         0.         1.        ]\n",
      " [0.95281693 0.92170064 0.90312495 ... 1.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#这里计算电影与电影的相似度\n",
    "\n",
    "item_similarity = pairwise_distances(user_movie_matrix.T,metric='cosine')\n",
    "print(item_similarity.shape)\n",
    "print(item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以上我们得到了用户与用户的相似度,那么理论上我们已经可以根据用户的相似度推荐商品了\n",
    "\n",
    "#同时我们很牛，我们也得到了电影与电影的相似度，那么理论上我们也可以选择根据电影的相似度推荐商品了\n",
    "\n",
    "#实际场景是用户会暴增,毕竟看流量的世界,用户越多越好,这就导致了用户的数量级恐怖上升,百万级已经很少了,\n",
    "#所以如果在这个量级上基于用户与用户的相似度去做推荐是非常不现实的\n",
    "\n",
    "#因此一般像电商这类的，商品顶多上去1万件了不起了，选择基于产品与产品的相似度去做推荐引擎是\n",
    "#更加明智和合理的做法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上面得到的相似度，可以在即时场景应用，比如：用户逛微博，然后点开了一个视频，那么我们推荐给他的其它视频\n",
    "#按照相似度去推\n",
    "\n",
    "#有2种方式，按相似度从大到小做推荐，确定一个阈值，大于这个阈值的推给该用户\n",
    "\n",
    "#我们的预测模型，预测用户会给电影打多少分，这个东西是用户没有点开任何东西，\n",
    "#我们在首页做推荐场景的时候用的，是长线推荐\n",
    "\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user': #如果type是user，则基于用户与用户的相似度，推测该用户对未评分的电影的评分\n",
    "        pred = similarity.dot(ratings) / np.array([np.abs(similarity.sum(axis=1))]).T\n",
    "        #被除数就是用户与用户的相似度（行）点乘 所有用户对某一个电影的评分（列）\n",
    "        #除数的长相[x\n",
    "        #         y],除数的每一行是每一个用户与其它用户相似度的和\n",
    "    elif type == 'item': #如果type是电影，则基于电影与电影的相似度。推测该用户对未评分的电影的评分\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        #被除数就是某一个用户对电影的评分（行）点乘 电影与电影的相似度（列）\n",
    "        #除数的长相是[x,y],每一列就是某一个电影与其它电影相似度的和\n",
    "    return pred #得到预测的矩阵\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "[[1.67437294e+00 3.43349631e-01 2.38970693e-01 ... 2.63729634e-03\n",
      "  2.09562375e-03 1.81808094e-03]\n",
      " [1.85328696e+00 4.74238792e-01 2.86377496e-01 ... 1.82071483e-03\n",
      "  3.28031113e-03 3.48678052e-03]\n",
      " [1.93413349e+00 4.67276838e-01 2.97058358e-01 ... 1.23728002e-03\n",
      "  3.26099444e-03 3.46463391e-03]\n",
      " ...\n",
      " [1.76113528e+00 4.44889039e-01 2.71815487e-01 ... 2.26853225e-03\n",
      "  3.04563616e-03 3.20638348e-03]\n",
      " [1.82156495e+00 4.16001047e-01 2.86652414e-01 ... 2.12869738e-03\n",
      "  2.73640943e-03 3.15369564e-03]\n",
      " [1.69421944e+00 3.35436519e-01 2.40751065e-01 ... 2.65489953e-03\n",
      "  2.08622458e-03 2.20269348e-03]]\n"
     ]
    }
   ],
   "source": [
    "#那么我们现在就开始预测吧\n",
    "\n",
    "user_prediction = predict(user_movie_matrix, user_similarity, type='user') #基于用户的相似度做预测\n",
    "print(user_prediction.shape)\n",
    "print(user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "[[0.44627765 0.475473   0.50593755 ... 0.58815455 0.5731069  0.56669645]\n",
      " [0.10854432 0.13295661 0.12558851 ... 0.13445801 0.13657587 0.13711081]\n",
      " [0.08568497 0.09169006 0.08764343 ... 0.08465892 0.08976784 0.09084451]\n",
      " ...\n",
      " [0.03230047 0.0450241  0.04292449 ... 0.05302764 0.0519099  0.05228033]\n",
      " [0.15777917 0.17409459 0.18900003 ... 0.19979296 0.19739388 0.20003117]\n",
      " [0.24767207 0.24489212 0.28263031 ... 0.34410424 0.33051406 0.33102478]]\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(user_movie_matrix, item_similarity, type='item') #基于电影的相似度做预测\n",
    "print(item_prediction.shape)\n",
    "print(item_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
